{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Eo6JXJiwRW-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import helper\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "path_data = 'drive/My Drive/turtle_recall/images'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSt64uH3wyTp",
        "outputId": "8081f5fc-0347-4e68-a920-0c5c2e471506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "dataset = torchvision.datasets.ImageFolder(path_data, transform= transform)"
      ],
      "metadata": {
        "id": "8h1vTNbF1MLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mean = 0.\n",
        "# std = 0.\n",
        "# nb_samples = 0.\n",
        "# # Iterate over the images in the dataset\n",
        "# for data, _ in dataset:\n",
        "#     # Get the shape of the data tensor\n",
        "#     shape = data.shape\n",
        "#     # Flatten the tensor to a 1D array\n",
        "#     data = data.view(data.size(0), -1)\n",
        "#     # Calculate the mean and standard deviation of the pixel values\n",
        "#     mean += data.mean(1)\n",
        "#     std += data.std(1)\n",
        "#     # Increment the sample count\n",
        "#     nb_samples += data.size(0)\n",
        "\n",
        "# # Calculate the mean and standard deviation of the entire dataset\n",
        "# mean /= nb_samples\n",
        "# std /= nb_samples\n",
        "\n",
        "# # Print the results\n",
        "# print(\"Mean:\", mean)\n",
        "# print(\"Standard deviation:\", std)"
      ],
      "metadata": {
        "id": "_s3fe9_OyXoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.Resize(255),\n",
        "                                transforms.CenterCrop(224),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                     std=[0.229, 0.224, 0.225])\n",
        "                                ]\n",
        "                               )\n"
      ],
      "metadata": {
        "id": "GGmnw6GO_KpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = torchvision.datasets.ImageFolder(path_data, transform=transform)"
      ],
      "metadata": {
        "id": "1rMcGFoaCIcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply randomcrop for train set and centercrop for test"
      ],
      "metadata": {
        "id": "2Nsvz6MrfI6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set, test_set = torch.utils.data.random_split(dataset, [1006, 112])\n",
        "train_set.transform = transforms.Compose([transforms.Resize(255),\n",
        "                                transforms.RandomCrop(224),\n",
        "                                transforms.RandomHorizontalFlip(),\n",
        "                                transforms.RandomVerticalFlip(),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                     std=[0.229, 0.224, 0.225])\n",
        "                                ]\n",
        "                               )"
      ],
      "metadata": {
        "id": "hLz7lw-FAdVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a data loader for the training set\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True, num_workers=4)\n",
        "\n",
        "# Create a data loader for the test set\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "# Create a dictionary of data loaders\n",
        "dataloaders = {'train': train_loader, 'test': test_loader}"
      ],
      "metadata": {
        "id": "1PrJ2gbQC4q-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7a1d7df-70bd-4cb4-d5c0-c7d994fe047e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter = iter(dataloaders['train'])\n",
        "images, labels = next(data_iter)"
      ],
      "metadata": {
        "id": "j-s31CRdE6RQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(  images[7].permute(1, 2, 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "DJqHo1v_I7dH",
        "outputId": "2a68b24f-a78f-4882-d1c2-1be3aeb07235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fbec69886a0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'resnet'\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = len(dataset.classes)\n",
        "print(f\"number of turtles: {num_classes}\")\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 32\n",
        "# Number of epochs to train for\n",
        "num_epochs = 50\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78I1LefmJcxL",
        "outputId": "1b04aced-1efa-49ad-f494-243790884a4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of turtles: 99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "      print('-' * 10)\n",
        "      for phase in ['train', 'test']:\n",
        "          if phase == 'train':\n",
        "              model.train()  # Set model to training mode\n",
        "          else:\n",
        "              model.eval()   # Set model to evaluate mode\n",
        "\n",
        "          running_loss = 0.0\n",
        "          running_corrects = 0\n",
        "\n",
        "          for inputs, labels in dataloaders[phase]:\n",
        "              inputs = inputs.to(device)\n",
        "              labels = labels.to(device)\n",
        "\n",
        "              optimizer.zero_grad()\n",
        "\n",
        "              with torch.set_grad_enabled(phase == 'train'):\n",
        "\n",
        "                  if is_inception and phase == 'train':\n",
        "\n",
        "                      outputs, aux_outputs = model(inputs)\n",
        "                      loss1 = criterion(outputs, labels)\n",
        "                      loss2 = criterion(aux_outputs, labels)\n",
        "                      loss = loss1 + 0.4*loss2\n",
        "                  else:\n",
        "                      outputs = model(inputs)\n",
        "                      loss = criterion(outputs, labels)\n",
        "\n",
        "                  _, preds = torch.max(outputs, 1)\n",
        "\n",
        "\n",
        "                  if phase == 'train':\n",
        "                      loss.backward()\n",
        "                      optimizer.step()\n",
        "\n",
        "           \n",
        "              running_loss += loss.item() * inputs.size(0)\n",
        "              running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "          epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "          epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "          print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "\n",
        "          if phase == 'test' and epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "          if phase == 'test':\n",
        "              val_acc_history.append(epoch_acc)\n",
        "    \n",
        "    # Use the scheduler to adjust the learning rate\n",
        "      # scheduler.step(epoch_loss)\n",
        "      # print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "metadata": {
        "id": "7pxvoIpgJ2xN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "metadata": {
        "id": "T2lplzXMKgU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's start by initialising the model\n",
        "!pip install timm\n",
        "from timm import create_model\n",
        "def initialize_model(num_classes, feature_extract, use_pretrained=True):\n",
        "\n",
        "    # model_ft = models.resnet50(pretrained=use_pretrained)\n",
        "    model_ft = create_model(\n",
        "            \"swin_tiny_patch4_window7_224\", pretrained=True, num_classes=num_classes, in_chans=3\n",
        "        )\n",
        "    # set_parameter_requires_grad(model_ft, feature_extract)\n",
        "    # num_ftrs = model_ft.fc.in_features\n",
        "    # model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "    input_size = 224\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "model_ft, input_size = initialize_model(num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "print(model_ft)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EclyZaYdKmrw",
        "outputId": "cd99bf34-e244-4815-e38a-cdbdc4bcf48c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 KB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from timm) (6.0)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.8/dist-packages (from timm) (1.13.0+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from timm) (0.14.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7->timm) (4.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (3.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (2.25.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (2.10)\n",
            "Installing collected packages: huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.11.1 timm-0.6.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Downloading: \"https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth\" to /root/.cache/torch/hub/checkpoints/swin_tiny_patch4_window7_224.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SwinTransformer(\n",
            "  (patch_embed): PatchEmbed(\n",
            "    (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
            "    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
            "  (layers): Sequential(\n",
            "    (0): BasicLayer(\n",
            "      (blocks): Sequential(\n",
            "        (0): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): Identity()\n",
            "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath(drop_prob=0.009)\n",
            "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (downsample): PatchMerging(\n",
            "        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicLayer(\n",
            "      (blocks): Sequential(\n",
            "        (0): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath(drop_prob=0.018)\n",
            "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath(drop_prob=0.027)\n",
            "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (downsample): PatchMerging(\n",
            "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
            "      )\n",
            "    )\n",
            "    (2): BasicLayer(\n",
            "      (blocks): Sequential(\n",
            "        (0): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath(drop_prob=0.036)\n",
            "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath(drop_prob=0.045)\n",
            "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath(drop_prob=0.055)\n",
            "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath(drop_prob=0.064)\n",
            "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath(drop_prob=0.073)\n",
            "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath(drop_prob=0.082)\n",
            "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (downsample): PatchMerging(\n",
            "        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
            "      )\n",
            "    )\n",
            "    (3): BasicLayer(\n",
            "      (blocks): Sequential(\n",
            "        (0): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath(drop_prob=0.091)\n",
            "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath(drop_prob=0.100)\n",
            "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (head): Linear(in_features=768, out_features=99, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print(model_ft)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDa0VnglKwcU",
        "outputId": "d453a90f-5165-4913-993b-8250ffc26f95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SwinTransformer(\n",
            "  (patch_embed): PatchEmbed(\n",
            "    (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
            "    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
            "  (layers): Sequential(\n",
            "    (0): BasicLayer(\n",
            "      (blocks): Sequential(\n",
            "        (0): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): Identity()\n",
            "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath(drop_prob=0.009)\n",
            "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (downsample): PatchMerging(\n",
            "        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicLayer(\n",
            "      (blocks): Sequential(\n",
            "        (0): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath(drop_prob=0.018)\n",
            "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath(drop_prob=0.027)\n",
            "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (downsample): PatchMerging(\n",
            "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
            "      )\n",
            "    )\n",
            "    (2): BasicLayer(\n",
            "      (blocks): Sequential(\n",
            "        (0): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath(drop_prob=0.036)\n",
            "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath(drop_prob=0.045)\n",
            "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath(drop_prob=0.055)\n",
            "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath(drop_prob=0.064)\n",
            "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath(drop_prob=0.073)\n",
            "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath(drop_prob=0.082)\n",
            "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (downsample): PatchMerging(\n",
            "        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
            "      )\n",
            "    )\n",
            "    (3): BasicLayer(\n",
            "      (blocks): Sequential(\n",
            "        (0): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath(drop_prob=0.091)\n",
            "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath(drop_prob=0.100)\n",
            "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (head): Linear(in_features=768, out_features=99, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model_ft.fc = nn.Linear(512, num_classes)"
      ],
      "metadata": {
        "id": "OrpyIVEVK40X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    print(\"GPU is not available\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbJB9sT5L8A9",
        "outputId": "dbd5bfb5-d4c4-403e-e347-a6b28db97d96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda'\n",
        "model_ft = model_ft.to(device)\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVstsiugMAYh",
        "outputId": "258ae18f-7819-436a-d5be-4028616a1a74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Params to learn:\n",
            "\t patch_embed.proj.weight\n",
            "\t patch_embed.proj.bias\n",
            "\t patch_embed.norm.weight\n",
            "\t patch_embed.norm.bias\n",
            "\t layers.0.blocks.0.norm1.weight\n",
            "\t layers.0.blocks.0.norm1.bias\n",
            "\t layers.0.blocks.0.attn.relative_position_bias_table\n",
            "\t layers.0.blocks.0.attn.qkv.weight\n",
            "\t layers.0.blocks.0.attn.qkv.bias\n",
            "\t layers.0.blocks.0.attn.proj.weight\n",
            "\t layers.0.blocks.0.attn.proj.bias\n",
            "\t layers.0.blocks.0.norm2.weight\n",
            "\t layers.0.blocks.0.norm2.bias\n",
            "\t layers.0.blocks.0.mlp.fc1.weight\n",
            "\t layers.0.blocks.0.mlp.fc1.bias\n",
            "\t layers.0.blocks.0.mlp.fc2.weight\n",
            "\t layers.0.blocks.0.mlp.fc2.bias\n",
            "\t layers.0.blocks.1.norm1.weight\n",
            "\t layers.0.blocks.1.norm1.bias\n",
            "\t layers.0.blocks.1.attn.relative_position_bias_table\n",
            "\t layers.0.blocks.1.attn.qkv.weight\n",
            "\t layers.0.blocks.1.attn.qkv.bias\n",
            "\t layers.0.blocks.1.attn.proj.weight\n",
            "\t layers.0.blocks.1.attn.proj.bias\n",
            "\t layers.0.blocks.1.norm2.weight\n",
            "\t layers.0.blocks.1.norm2.bias\n",
            "\t layers.0.blocks.1.mlp.fc1.weight\n",
            "\t layers.0.blocks.1.mlp.fc1.bias\n",
            "\t layers.0.blocks.1.mlp.fc2.weight\n",
            "\t layers.0.blocks.1.mlp.fc2.bias\n",
            "\t layers.0.downsample.norm.weight\n",
            "\t layers.0.downsample.norm.bias\n",
            "\t layers.0.downsample.reduction.weight\n",
            "\t layers.1.blocks.0.norm1.weight\n",
            "\t layers.1.blocks.0.norm1.bias\n",
            "\t layers.1.blocks.0.attn.relative_position_bias_table\n",
            "\t layers.1.blocks.0.attn.qkv.weight\n",
            "\t layers.1.blocks.0.attn.qkv.bias\n",
            "\t layers.1.blocks.0.attn.proj.weight\n",
            "\t layers.1.blocks.0.attn.proj.bias\n",
            "\t layers.1.blocks.0.norm2.weight\n",
            "\t layers.1.blocks.0.norm2.bias\n",
            "\t layers.1.blocks.0.mlp.fc1.weight\n",
            "\t layers.1.blocks.0.mlp.fc1.bias\n",
            "\t layers.1.blocks.0.mlp.fc2.weight\n",
            "\t layers.1.blocks.0.mlp.fc2.bias\n",
            "\t layers.1.blocks.1.norm1.weight\n",
            "\t layers.1.blocks.1.norm1.bias\n",
            "\t layers.1.blocks.1.attn.relative_position_bias_table\n",
            "\t layers.1.blocks.1.attn.qkv.weight\n",
            "\t layers.1.blocks.1.attn.qkv.bias\n",
            "\t layers.1.blocks.1.attn.proj.weight\n",
            "\t layers.1.blocks.1.attn.proj.bias\n",
            "\t layers.1.blocks.1.norm2.weight\n",
            "\t layers.1.blocks.1.norm2.bias\n",
            "\t layers.1.blocks.1.mlp.fc1.weight\n",
            "\t layers.1.blocks.1.mlp.fc1.bias\n",
            "\t layers.1.blocks.1.mlp.fc2.weight\n",
            "\t layers.1.blocks.1.mlp.fc2.bias\n",
            "\t layers.1.downsample.norm.weight\n",
            "\t layers.1.downsample.norm.bias\n",
            "\t layers.1.downsample.reduction.weight\n",
            "\t layers.2.blocks.0.norm1.weight\n",
            "\t layers.2.blocks.0.norm1.bias\n",
            "\t layers.2.blocks.0.attn.relative_position_bias_table\n",
            "\t layers.2.blocks.0.attn.qkv.weight\n",
            "\t layers.2.blocks.0.attn.qkv.bias\n",
            "\t layers.2.blocks.0.attn.proj.weight\n",
            "\t layers.2.blocks.0.attn.proj.bias\n",
            "\t layers.2.blocks.0.norm2.weight\n",
            "\t layers.2.blocks.0.norm2.bias\n",
            "\t layers.2.blocks.0.mlp.fc1.weight\n",
            "\t layers.2.blocks.0.mlp.fc1.bias\n",
            "\t layers.2.blocks.0.mlp.fc2.weight\n",
            "\t layers.2.blocks.0.mlp.fc2.bias\n",
            "\t layers.2.blocks.1.norm1.weight\n",
            "\t layers.2.blocks.1.norm1.bias\n",
            "\t layers.2.blocks.1.attn.relative_position_bias_table\n",
            "\t layers.2.blocks.1.attn.qkv.weight\n",
            "\t layers.2.blocks.1.attn.qkv.bias\n",
            "\t layers.2.blocks.1.attn.proj.weight\n",
            "\t layers.2.blocks.1.attn.proj.bias\n",
            "\t layers.2.blocks.1.norm2.weight\n",
            "\t layers.2.blocks.1.norm2.bias\n",
            "\t layers.2.blocks.1.mlp.fc1.weight\n",
            "\t layers.2.blocks.1.mlp.fc1.bias\n",
            "\t layers.2.blocks.1.mlp.fc2.weight\n",
            "\t layers.2.blocks.1.mlp.fc2.bias\n",
            "\t layers.2.blocks.2.norm1.weight\n",
            "\t layers.2.blocks.2.norm1.bias\n",
            "\t layers.2.blocks.2.attn.relative_position_bias_table\n",
            "\t layers.2.blocks.2.attn.qkv.weight\n",
            "\t layers.2.blocks.2.attn.qkv.bias\n",
            "\t layers.2.blocks.2.attn.proj.weight\n",
            "\t layers.2.blocks.2.attn.proj.bias\n",
            "\t layers.2.blocks.2.norm2.weight\n",
            "\t layers.2.blocks.2.norm2.bias\n",
            "\t layers.2.blocks.2.mlp.fc1.weight\n",
            "\t layers.2.blocks.2.mlp.fc1.bias\n",
            "\t layers.2.blocks.2.mlp.fc2.weight\n",
            "\t layers.2.blocks.2.mlp.fc2.bias\n",
            "\t layers.2.blocks.3.norm1.weight\n",
            "\t layers.2.blocks.3.norm1.bias\n",
            "\t layers.2.blocks.3.attn.relative_position_bias_table\n",
            "\t layers.2.blocks.3.attn.qkv.weight\n",
            "\t layers.2.blocks.3.attn.qkv.bias\n",
            "\t layers.2.blocks.3.attn.proj.weight\n",
            "\t layers.2.blocks.3.attn.proj.bias\n",
            "\t layers.2.blocks.3.norm2.weight\n",
            "\t layers.2.blocks.3.norm2.bias\n",
            "\t layers.2.blocks.3.mlp.fc1.weight\n",
            "\t layers.2.blocks.3.mlp.fc1.bias\n",
            "\t layers.2.blocks.3.mlp.fc2.weight\n",
            "\t layers.2.blocks.3.mlp.fc2.bias\n",
            "\t layers.2.blocks.4.norm1.weight\n",
            "\t layers.2.blocks.4.norm1.bias\n",
            "\t layers.2.blocks.4.attn.relative_position_bias_table\n",
            "\t layers.2.blocks.4.attn.qkv.weight\n",
            "\t layers.2.blocks.4.attn.qkv.bias\n",
            "\t layers.2.blocks.4.attn.proj.weight\n",
            "\t layers.2.blocks.4.attn.proj.bias\n",
            "\t layers.2.blocks.4.norm2.weight\n",
            "\t layers.2.blocks.4.norm2.bias\n",
            "\t layers.2.blocks.4.mlp.fc1.weight\n",
            "\t layers.2.blocks.4.mlp.fc1.bias\n",
            "\t layers.2.blocks.4.mlp.fc2.weight\n",
            "\t layers.2.blocks.4.mlp.fc2.bias\n",
            "\t layers.2.blocks.5.norm1.weight\n",
            "\t layers.2.blocks.5.norm1.bias\n",
            "\t layers.2.blocks.5.attn.relative_position_bias_table\n",
            "\t layers.2.blocks.5.attn.qkv.weight\n",
            "\t layers.2.blocks.5.attn.qkv.bias\n",
            "\t layers.2.blocks.5.attn.proj.weight\n",
            "\t layers.2.blocks.5.attn.proj.bias\n",
            "\t layers.2.blocks.5.norm2.weight\n",
            "\t layers.2.blocks.5.norm2.bias\n",
            "\t layers.2.blocks.5.mlp.fc1.weight\n",
            "\t layers.2.blocks.5.mlp.fc1.bias\n",
            "\t layers.2.blocks.5.mlp.fc2.weight\n",
            "\t layers.2.blocks.5.mlp.fc2.bias\n",
            "\t layers.2.downsample.norm.weight\n",
            "\t layers.2.downsample.norm.bias\n",
            "\t layers.2.downsample.reduction.weight\n",
            "\t layers.3.blocks.0.norm1.weight\n",
            "\t layers.3.blocks.0.norm1.bias\n",
            "\t layers.3.blocks.0.attn.relative_position_bias_table\n",
            "\t layers.3.blocks.0.attn.qkv.weight\n",
            "\t layers.3.blocks.0.attn.qkv.bias\n",
            "\t layers.3.blocks.0.attn.proj.weight\n",
            "\t layers.3.blocks.0.attn.proj.bias\n",
            "\t layers.3.blocks.0.norm2.weight\n",
            "\t layers.3.blocks.0.norm2.bias\n",
            "\t layers.3.blocks.0.mlp.fc1.weight\n",
            "\t layers.3.blocks.0.mlp.fc1.bias\n",
            "\t layers.3.blocks.0.mlp.fc2.weight\n",
            "\t layers.3.blocks.0.mlp.fc2.bias\n",
            "\t layers.3.blocks.1.norm1.weight\n",
            "\t layers.3.blocks.1.norm1.bias\n",
            "\t layers.3.blocks.1.attn.relative_position_bias_table\n",
            "\t layers.3.blocks.1.attn.qkv.weight\n",
            "\t layers.3.blocks.1.attn.qkv.bias\n",
            "\t layers.3.blocks.1.attn.proj.weight\n",
            "\t layers.3.blocks.1.attn.proj.bias\n",
            "\t layers.3.blocks.1.norm2.weight\n",
            "\t layers.3.blocks.1.norm2.bias\n",
            "\t layers.3.blocks.1.mlp.fc1.weight\n",
            "\t layers.3.blocks.1.mlp.fc1.bias\n",
            "\t layers.3.blocks.1.mlp.fc2.weight\n",
            "\t layers.3.blocks.1.mlp.fc2.bias\n",
            "\t norm.weight\n",
            "\t norm.bias\n",
            "\t head.weight\n",
            "\t head.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "# Early stoping is also a method for preventing overfitting\n",
        "optimizer = optim.AdamW(model_ft.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "# scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=20, eta_min= 1e-4)"
      ],
      "metadata": {
        "id": "0B62Z9Qan0jL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import copy\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train and evaluate\n",
        "model_ft, hist = train_model(model_ft, dataloaders, criterion, optimizer, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZJNlMi-MGA1",
        "outputId": "51db749b-1b47-41bd-fbf9-841dc465f011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 4.5117 Acc: 0.0358\n",
            "test Loss: 4.4314 Acc: 0.0179\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 4.2253 Acc: 0.0775\n",
            "test Loss: 4.1071 Acc: 0.0804\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 3.4089 Acc: 0.2177\n",
            "test Loss: 3.5835 Acc: 0.1964\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 2.0712 Acc: 0.5547\n",
            "test Loss: 3.2335 Acc: 0.2411\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.9189 Acc: 0.8618\n",
            "test Loss: 2.8049 Acc: 0.3304\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.3777 Acc: 0.9742\n",
            "test Loss: 2.6963 Acc: 0.3750\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.2176 Acc: 0.9881\n",
            "test Loss: 2.5888 Acc: 0.4018\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.1253 Acc: 0.9980\n",
            "test Loss: 2.5619 Acc: 0.3929\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.0953 Acc: 0.9990\n",
            "test Loss: 2.5469 Acc: 0.4196\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.0945 Acc: 0.9950\n",
            "test Loss: 2.5219 Acc: 0.4196\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.0635 Acc: 0.9970\n",
            "test Loss: 2.6897 Acc: 0.4018\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.0616 Acc: 0.9980\n",
            "test Loss: 2.6434 Acc: 0.4286\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.0581 Acc: 1.0000\n",
            "test Loss: 2.5645 Acc: 0.4107\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.0416 Acc: 1.0000\n",
            "test Loss: 2.4796 Acc: 0.4107\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.0521 Acc: 0.9980\n",
            "test Loss: 2.5343 Acc: 0.3661\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.0371 Acc: 1.0000\n",
            "test Loss: 2.4584 Acc: 0.3839\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.0343 Acc: 0.9990\n",
            "test Loss: 2.5033 Acc: 0.4375\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.0322 Acc: 0.9980\n",
            "test Loss: 2.4881 Acc: 0.4554\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.0364 Acc: 0.9990\n",
            "test Loss: 2.4395 Acc: 0.4554\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.0318 Acc: 0.9980\n",
            "test Loss: 2.5916 Acc: 0.4375\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.0436 Acc: 0.9970\n",
            "test Loss: 2.5645 Acc: 0.4554\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.0260 Acc: 0.9990\n",
            "test Loss: 2.5977 Acc: 0.4375\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.0331 Acc: 0.9990\n",
            "test Loss: 2.6880 Acc: 0.4464\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.0243 Acc: 0.9990\n",
            "test Loss: 2.6091 Acc: 0.4464\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.0297 Acc: 0.9990\n",
            "test Loss: 2.5698 Acc: 0.4375\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.0251 Acc: 1.0000\n",
            "test Loss: 2.6936 Acc: 0.4196\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.0163 Acc: 1.0000\n",
            "test Loss: 2.5367 Acc: 0.4643\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.0167 Acc: 1.0000\n",
            "test Loss: 2.5492 Acc: 0.4464\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.0199 Acc: 0.9980\n",
            "test Loss: 2.6849 Acc: 0.4107\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.0199 Acc: 0.9990\n",
            "test Loss: 2.6604 Acc: 0.4286\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.0123 Acc: 1.0000\n",
            "test Loss: 2.7481 Acc: 0.4107\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 0.0142 Acc: 0.9990\n",
            "test Loss: 2.6268 Acc: 0.4286\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 0.0127 Acc: 0.9990\n",
            "test Loss: 2.7162 Acc: 0.4018\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 0.0146 Acc: 0.9990\n",
            "test Loss: 2.5847 Acc: 0.4286\n",
            "Epoch 34/49\n",
            "----------\n",
            "train Loss: 0.0128 Acc: 1.0000\n",
            "test Loss: 2.5869 Acc: 0.4554\n",
            "Epoch 35/49\n",
            "----------\n",
            "train Loss: 0.0178 Acc: 0.9990\n",
            "test Loss: 2.7599 Acc: 0.4911\n",
            "Epoch 36/49\n",
            "----------\n",
            "train Loss: 0.0127 Acc: 1.0000\n",
            "test Loss: 2.6517 Acc: 0.4107\n",
            "Epoch 37/49\n",
            "----------\n",
            "train Loss: 0.0122 Acc: 1.0000\n",
            "test Loss: 2.5103 Acc: 0.4375\n",
            "Epoch 38/49\n",
            "----------\n",
            "train Loss: 0.0128 Acc: 0.9990\n",
            "test Loss: 2.4141 Acc: 0.4643\n",
            "Epoch 39/49\n",
            "----------\n",
            "train Loss: 0.0132 Acc: 0.9980\n",
            "test Loss: 2.5814 Acc: 0.4732\n",
            "Epoch 40/49\n",
            "----------\n",
            "train Loss: 0.0207 Acc: 0.9970\n",
            "test Loss: 2.5617 Acc: 0.4643\n",
            "Epoch 41/49\n",
            "----------\n",
            "train Loss: 0.0621 Acc: 0.9861\n",
            "test Loss: 3.1778 Acc: 0.3304\n",
            "Epoch 42/49\n",
            "----------\n",
            "train Loss: 0.0843 Acc: 0.9801\n",
            "test Loss: 3.4852 Acc: 0.3214\n",
            "Epoch 43/49\n",
            "----------\n",
            "train Loss: 0.0844 Acc: 0.9831\n",
            "test Loss: 3.1229 Acc: 0.3393\n",
            "Epoch 44/49\n",
            "----------\n",
            "train Loss: 0.0801 Acc: 0.9851\n",
            "test Loss: 3.2802 Acc: 0.3214\n",
            "Epoch 45/49\n",
            "----------\n",
            "train Loss: 0.0508 Acc: 0.9940\n",
            "test Loss: 2.8485 Acc: 0.4375\n",
            "Epoch 46/49\n",
            "----------\n",
            "train Loss: 0.0328 Acc: 0.9930\n",
            "test Loss: 3.2372 Acc: 0.3482\n",
            "Epoch 47/49\n",
            "----------\n",
            "train Loss: 0.0314 Acc: 0.9970\n",
            "test Loss: 3.0414 Acc: 0.3661\n",
            "Epoch 48/49\n",
            "----------\n",
            "train Loss: 0.0150 Acc: 0.9980\n",
            "test Loss: 2.9790 Acc: 0.3661\n",
            "Epoch 49/49\n",
            "----------\n",
            "train Loss: 0.0152 Acc: 0.9990\n",
            "test Loss: 2.9389 Acc: 0.4107\n",
            "Training complete in 36m 11s\n",
            "Best val Acc: 0.491071\n"
          ]
        }
      ]
    }
  ]
}